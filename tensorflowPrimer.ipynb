{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Details about the definitions below:\n",
    "------\n",
    " - **`keras.models.Sequential`**: A sequence of layers\n",
    " - **`keras.layers.Flatten`**: Flatten a ndarry into a 1-dimensional array\n",
    " - **`keras.layers.Dense`**: A dense neural network layer\n",
    " - **`model.evaluate(test_data)`** vs **`model.predict(test_data)`**: Predict will output the prediction (e.g. the final output estimate of *y* (e.g. the output is the vector *y*), whereas evaluate will calculate the loss function and any metrics (the output is a vector of loss function + these metrics).\n",
    "\n",
    "**Optimizer**:\n",
    " - `'adam'`: \n",
    " - `'sgd'`: Stochastic Gradient Descent\n",
    "\n",
    "**Loss**: The loss function to minimize. Options are:\n",
    " - `'mean_squared_error'` (like it sounds)\n",
    "\n",
    "**Metrics**: These are quantities that are calculated alongside the evaluation, for your convenience. You can add as many of these as you like. Examples:\n",
    " - Probabilistic metrics:\n",
    "   - XXXCrossEntropy: \n",
    "   - KLDivergence:\n",
    "   - Poisson:\n",
    " - Regression metrics:\n",
    "   - MeanSquaredError (and variations)\n",
    "   - MeanSquaredLogarithmicError\n",
    "   \n",
    "**Callbacks**: During model fitting, a callback is run after each epoch to e.g. stop the training once the descired accuracy is reached.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Front Matter\n",
    "========\n",
    "\n",
    "This is a quick notebook to explore the outputs of the Keras model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "%load_ext tensorboard\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make an example dataset\n",
    "========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nPoints = 1000\n",
    "x_sig = 1 * np.random.randn(nPoints) + 1\n",
    "y_sig = 1 * np.random.randn(nPoints) + 1\n",
    "x_bkg = 1 * np.random.randn(nPoints*10) - 1\n",
    "y_bkg = 1 * np.random.randn(nPoints*10) - 1\n",
    "label = np.append(np.ones(len(x_sig)),np.zeros(len(x_bkg))).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(np.append(x_sig,x_bkg),\n",
    "                           np.append(y_sig,y_bkg),\n",
    "                           label)),columns=['x','y','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df,vars=['x', 'y'],hue='label');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot correlations of variables\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = sns.heatmap(df[df['label'] == 1][['x','y']].corr(),annot=True,vmin=-1,vmax=1)\n",
    "b, t = plt.ylim() # discover the values for bottom and top\n",
    "plt.ylim(b + 0.5, t - 0.5) # update the ylim(bottom, top) values\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the Keras Model, compile and fit\n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "#    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(5, name='first_dense', input_shape=(2,), activation='relu'),\n",
    "    tf.keras.layers.Dense(5, name='middle_dense', activation='relu'),\n",
    "#    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1, name='last_dense', activation='sigmoid') # sigmoid for binary; softmax for multi?\n",
    "    ])\n",
    "\n",
    "##### TODO:\n",
    "#probability_model = tf.keras.Sequential([\n",
    "#  model,\n",
    "#  tf.keras.layers.Softmax()\n",
    "#])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    df[['x','y']].values,\n",
    "    df['label'].values,\n",
    "    batch_size=64,\n",
    "    epochs=20,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the Model Structure\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pydot as pyd\n",
    "#import graphviz\n",
    "#tf.keras.utils.plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True,\n",
    "#    rankdir='TB', expand_nested=True, dpi=96)\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 1\n",
    "# from IPython.display import SVG\n",
    "# SVG(tf.keras.utils.model_to_dot(model,expand_nested=True).create(prog='dot', format='svg'))\n",
    "# version 2\n",
    "#tf.keras.utils.plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True,expand_nested=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the performance\n",
    "==========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.metrics_names)\n",
    "model.evaluate(df[['x','y']].values,df['label'].values,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This sets things as 1 or 0\n",
    "# based on whether or not is is above or below 0.5\n",
    "df['binary_prediction'] = model.predict_classes(df[['x','y']].values)\n",
    "# This is the continuous variable\n",
    "df['discriminant'] = model.predict(df[['x','y']].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(df['binary_prediction'].values,df['label'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the raw discriminants\n",
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df[df['label'] ==0]['discriminant'],bins=20,label='bkg',density=True,histtype='step',lw=2)\n",
    "plt.hist(df[df['label'] ==1]['discriminant'],bins=20,label='sig',density=True,histtype='step',lw=2)\n",
    "plt.legend()\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC Curve\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(df['label'].values, df['discriminant'].values)\n",
    "from sklearn.metrics import auc\n",
    "auc_keras = auc(fpr_keras, tpr_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc_keras))\n",
    "plt.ylabel('signal efficiency (true positive rate)')\n",
    "plt.xlabel('bkg efficiency (false positive rate)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-D Gradients\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since probability is a continuous value from 0 to 1, we are getting many contours.\n",
    "#If your visualization is restricted to 2 classes (output is 2D softmax vector) you can use this simple code\n",
    "\n",
    "def plotModelOut(x,y,model):\n",
    "    '''\n",
    "    x,y: 2D MeshGrid input\n",
    "    model: Keras Model API Object\n",
    "    '''\n",
    "    grid = np.stack((x,y))\n",
    "    grid = grid.T.reshape(-1,2)\n",
    "    outs = model.predict(grid)\n",
    "    y1 = outs.T[0].reshape(x.shape[0],x.shape[0])\n",
    "    plt.contourf(x,y,y1,cmap='binary')\n",
    "    plt.colorbar()\n",
    "\n",
    "    #plt.show()\n",
    "\n",
    "xx, yy = np.meshgrid(np.linspace(-4,4,100), np.linspace(-4,4,100))\n",
    "plotModelOut(xx,yy,model)\n",
    "\n",
    "plt.scatter(df['x'][df['label'] == 0],df['y'][df['label'] == 0])\n",
    "plt.scatter(df['x'][df['label'] == 1],df['y'][df['label'] == 1])\n",
    "\n",
    "plt.xlim([-4,4])\n",
    "plt.ylim([-4,4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Hello World of Neural Networks\n",
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([tf.keras.layers.Dense(units=1, input_shape=[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0],dtype=float)\n",
    "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0],dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(xs, ys, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.predict([10.0,11.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST Dataset\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_images.shape,test_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the data:\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "test_images  = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_images[0])\n",
    "#print(train_images[0])\n",
    "#print(train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([keras.layers.Flatten(), # Optional: specifying shape, e.g. input_shape=(28,28)\n",
    "                          keras.layers.Dense(512,activation=tf.nn.relu), # Try 128, 1024, ...\n",
    "                          keras.layers.Dense(256,activation=tf.nn.relu), # Try 128, 1024, ...\n",
    "                          keras.layers.Dense(10,activation=tf.nn.softmax)]) # 10 should match the output type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= tf.optimizers.Adam(),\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a callback to our fitting step in order to sto \n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('accuracy')>0.6):\n",
    "      print(\"\\nReached 60% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "callback = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_images,train_labels,epochs=5,callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_images,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These predictions are the scores for each of the 10 categories, for the first test image.\n",
    "# As you can see, \"9\" is the winner.\n",
    "classifications = model.predict(test_images)\n",
    "print(classifications[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handwriting MNIST\n",
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: train_mnist\n",
    "def train_mnist():\n",
    "    # Please write your code only where you are indicated.\n",
    "    # please do not remove # model fitting inline comments.\n",
    "\n",
    "    # YOUR CODE SHOULD START HERE\n",
    "    class myCallback(tf.keras.callbacks.Callback):\n",
    "      def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy')>=0.99):\n",
    "          print(\"\\nReached 99% accuracy so cancelling training!\")\n",
    "          self.model.stop_training = True\n",
    "\n",
    "    callback = myCallback()\n",
    "    # YOUR CODE SHOULD END HERE\n",
    "\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "\n",
    "    (x_train, y_train),(x_test, y_test) = mnist.load_data(path='mnist.npz')\n",
    "    # YOUR CODE SHOULD START HERE\n",
    "    x_train = x_train / 255.0 # normalize the data to between 0 and 1\n",
    "    x_test  = x_test / 255.0 # normalize the data to between 0 and 1\n",
    "    # YOUR CODE SHOULD END HERE\n",
    "    model = tf.keras.models.Sequential([\n",
    "        # YOUR CODE SHOULD START HERE\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(128,activation=tf.nn.relu),\n",
    "        keras.layers.Dense(10,activation=tf.nn.softmax)\n",
    "        # YOUR CODE SHOULD END HERE\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # model fitting\n",
    "    history = model.fit(# YOUR CODE SHOULD START HERE\n",
    "        x_train,y_train,epochs=11,callbacks=[callback]\n",
    "              # YOUR CODE SHOULD END HERE\n",
    "    )\n",
    "    # model fitting\n",
    "    return history.epoch, history.history['accuracy'][-1]\n",
    "\n",
    "train_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train),(x_test, y_test) = mnist.load_data(path='mnist.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train[0])\n",
    "plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Neural Networks\n",
    "----------\n",
    "\n",
    "**Note that the Coursera people wanted you to run this using GPUs in Colab. If you run it locally, your computer's fan starts running.**\n",
    "\n",
    " - The `CONV2D` layer runs a bunch of filters (the number of filters is specified by the first argument) on top of the \n",
    "   - Note that specifying `'relu'` will toss out negative numbers. Interesting.\n",
    " - The `MaxPool2D` layer finds the maximum value in a window.\n",
    " \n",
    "An interesting idea I heard was to **start with not so many filters in the first Conv2D layer**, and then as you continue to pool (and therefore reduce the size of the image) you should **add more filters to learn in later Conv2D layers.**. Therefore, the number of parameters does not explode, and you have more opportunities for discovering interesting features in the final convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images=training_images.reshape(60000, 28, 28, 1)\n",
    "training_images=training_images / 255.0\n",
    "\n",
    "test_images = test_images.reshape(10000, 28, 28, 1)\n",
    "test_images=test_images/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "test_loss = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(3,4,figsize=(12,8))\n",
    "\n",
    "FIRST_IMAGE=0\n",
    "SECOND_IMAGE=7\n",
    "THIRD_IMAGE=26\n",
    "CONVOLUTION_NUMBER = 3\n",
    "\n",
    "from tensorflow.keras import models\n",
    "\n",
    "layer_outputs = [layer.output for layer in model.layers]\n",
    "activation_model = tf.keras.models.Model(inputs = model.input, outputs = layer_outputs)\n",
    "\n",
    "for x in range(0,4):\n",
    "    f1 = activation_model.predict(test_images[FIRST_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "    axarr[0,x].imshow(f1[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
    "    axarr[0,x].grid(False)\n",
    "    f2 = activation_model.predict(test_images[SECOND_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "    axarr[1,x].imshow(f2[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
    "    axarr[1,x].grid(False)\n",
    "    f3 = activation_model.predict(test_images[THIRD_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "    axarr[2,x].imshow(f3[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
    "    axarr[2,x].grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment: Convolutional Neural Networks and (handwriting) MNIST\n",
    "----------\n",
    "\n",
    "Very similar to what you did above. Some interesting code snippet though:\n",
    "\n",
    "```python\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "```\n",
    "\n",
    "Something to look into.... interesting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
