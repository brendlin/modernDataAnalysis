{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Time series] Forecasting\n",
    "=========\n",
    "\n",
    "Forecasting involves predicting the behavior of a variable that typically has some **stochastic** element.\n",
    "\n",
    "A key distinction relates to whether we are forecasting based on **extrapolating a single variable**, or using a **multivariate** approach to improve the forecasting model.\n",
    "\n",
    "A key concept is **periodicity** or **seasonality** -- periodic repeating patterns in the data that must be accounted for. Commonly quoted is the **STL decomposition** (seasonality, trend, residual):\n",
    "\n",
    "$y(t) = S(t) + T(t) + R(t)$\n",
    "\n",
    "\n",
    "Terminology:\n",
    "-----------\n",
    " - **Trend**: the (non-seasonal) pattern in the data\n",
    " - **Seasonality**: the seasonal (periodic) variation in the data (also weekly, monthly trends)\n",
    " - **Cyclic**: Patterns that are not of a fixed frequency. An example is the ups and downs of the \"business cycle\".\n",
    "\n",
    "Forecasting Tools:\n",
    "-------\n",
    " - Decomposition models:\n",
    " - Smoothing models:\n",
    " - **(S)ARIMA models (Auto-Regressive Integrated Moving Average)**: \n",
    " - **TBATS**: Trigonometric, Box-Cox transform, ARMA errors, Trend and Seasonal Components. Able to account for multiple seasonalities (e.g. weekly and yearly simultaneously)\n",
    " - **NNETAR (Neural Network AutoRegression)**\n",
    " - **LSTMs**: typically not used for a single trend forecast, but instead works well with a lot of input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "import urllib\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting Time Series\n",
    "=====\n",
    " - See `plotting.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datetime\n",
    "======\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_date = '2016-05-01 12:00'\n",
    "\n",
    "# strptime: \"string-parse time\"\n",
    "datetime_obj = datetime.strptime(string_date,'%Y-%m-%d %H:%M')\n",
    "\n",
    "# strftime: \"string-format time\"\n",
    "string_date_1 = datetime.strftime(datetime_obj,'%Y-%m-%d %H:%M')\n",
    "\n",
    "assert string_date == string_date_1, 'Something went wrong.'\n",
    "string_date_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = datetime.now()\n",
    "\n",
    "# Translate \"now\" into \"the beginning of today\"\n",
    "start_of_day = tm - timedelta(hours=tm.hour,\n",
    "                              minutes=tm.minute,\n",
    "                              seconds=tm.second,\n",
    "                              microseconds=tm.microsecond)\n",
    "\n",
    "# This will give you a DatetimeIndex type of panda Series\n",
    "# with 15 minute time intervals\n",
    "datelist = pd.date_range(start_of_day, periods=5, freq='15T')\n",
    "\n",
    "# This will initiate a pandas dataframe with the dates as the index.\n",
    "df = datelist.to_frame(name='dateTime')\n",
    "df['dateTime_str'] = df.index.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# This will rather clumsily add both as columns, with normal integer indices\n",
    "df2 = pd.DataFrame()\n",
    "df2['dateTime_str'] = datelist.strftime('%Y-%m-%d %H:%M:%S')\n",
    "df2['dateTime_dt'] = pd.to_datetime(df2['dateTime_str'])\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dealing with Time zones\n",
    "--------\n",
    "\n",
    "We use pytz to specify a timezone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz\n",
    "for tz in pytz.all_timezones:\n",
    "    if 'Europe' not in tz :\n",
    "        continue\n",
    "    print(tz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "String data with no timezone info\n",
    "----\n",
    "Say you have a timeseries with no timezone info. If you know the origin of the data, you can specify what timezone that data is from by calling `tz_localize` to convert it into a Datetime that is now continuous in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMEZONE='Europe/Paris'\n",
    "tz_object = pytz.timezone(TIMEZONE)\n",
    "\n",
    "datelist = ['30.10.2016 01:45',\n",
    "            '30.10.2016 02:00',\n",
    "            '30.10.2016 02:15',\n",
    "            '30.10.2016 02:30',\n",
    "            '30.10.2016 02:45',\n",
    "            '30.10.2016 02:00',\n",
    "            '30.10.2016 02:15',\n",
    "            '30.10.2016 02:30',\n",
    "            '30.10.2016 02:45',\n",
    "            '30.10.2016 03:00',\n",
    "            '30.10.2016 03:15',\n",
    "           ]\n",
    "\n",
    "datelist_dt = pd.to_datetime(datelist)\n",
    "datelist_dt.tz_localize(TIMEZONE,ambiguous='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datelist_dt[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rolling Average\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'https://raw.githubusercontent.com/antoinecarme/TimeSeriesData/master/fpp2/elecequip.csv'\n",
    "urllib.request.urlretrieve(filename, os.path.split(filename)[-1])\n",
    "\n",
    "df = pd.read_csv('elecequip.csv')\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(16, 6))\n",
    "ax.plot(df['Index'],df['x'])\n",
    "ax.plot(df['Index'],df['x'].rolling(window=12,center=True,min_periods=1).mean(),label='rolling average',color='red')\n",
    "ax.plot(df['Index'],df['x'].diff().fillna(0))\n",
    "\n",
    "ax.set_xlabel('year')\n",
    "ax.set_ylabel('new orders index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data monthly\n",
    "df['Month'] = (df['Index'] % 1 )*12\n",
    "df_byMonth = df.groupby('Month').mean()\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(df_byMonth.index,df_byMonth['x'])\n",
    "ax.set_xlabel('Month')\n",
    "ax.set_ylabel('<new orders index>')\n",
    "df_byMonth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seasonal Decompose (\"statsmodels\" package)\n",
    "=======\n",
    "\n",
    "This function essentially applies a rolling average of sorts to the data in order to extract the larger trend, and then subtracts this trend from the data. The seasonality is then the mean in each month of this subtracted data. Finally, the residual is the remainder with the monthly periodic trend subtracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runStatsModels() :\n",
    "    from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "    result = seasonal_decompose(df['x'], model='additive', period=12)\n",
    "\n",
    "    fig, (ax1,ax2,ax3,ax4) = plt.subplots(4,1, figsize=(10,20))\n",
    "    ax1.plot(result.observed); ax1.set_xlabel('observed')\n",
    "    ax2.plot(result.trend); ax2.set_xlabel('trend')\n",
    "    ax2.plot(df['x'].rolling(window=12,center=True,min_periods=1).mean())\n",
    "    ax3.plot(result.resid); ax3.set_xlabel('resid')\n",
    "    ax4.plot(result.seasonal[:24]); ax4.set_xlabel('seasonal')\n",
    "    ax4.plot(df_byMonth['x']-95)\n",
    "\n",
    "#runStatsModels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autocorrelation\n",
    "=========\n",
    "\n",
    "See also the Hida Challenge description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(16, 6))\n",
    "pd.plotting.autocorrelation_plot(df['x'],ax=ax,label='autocorrelation of data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bibliography\n",
    "-------\n",
    "\n",
    " - Hyndman & Athanasopoulos, **Forecasting: Principles and Practice**, https://otexts.com/fpp2/\n",
    " - Davide Burba, https://towardsdatascience.com/an-overview-of-time-series-forecasting-models-a2fa7a358fcb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
