{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terminology\n",
    "======\n",
    "\n",
    " - **REST API/RESTful**: A web service that uses the \"REST\" (representational state transfer) architectual style. This style uses a subset of HTTP. It can use a variety of data formats, e.g. json.\n",
    "   - Scalable and stateless\n",
    "   - High performance, largely due to **caching**\n",
    "   - Consists of resources\n",
    "   - REQUEST and RESPONSE \n",
    "     - REQEST consists of CRUD (Create, Read, Update, Delete) operations\n",
    "     - POST (Create)\n",
    "     - GET (Read)\n",
    "     - PUT (Update)\n",
    "     - DELETE (Delete)\n",
    "     - REQUEST: Header, Operator, Endpoint, Parameter/body\n",
    "     - RESPONSE: usually in json format\n",
    "\n",
    "\n",
    " - **SOAP**: A (different) web messaging protocol specification that uses XML as its message format (and ONLY xml).\n",
    " - **WSGI**: WSGI is the Web Server Gateway Interface. It is a specification that describes how a web server communicates with web applications, and how web applications can be chained together to process one request.\n",
    "\n",
    "\n",
    " - **CapEx** (Capital Expenditure): Up-front purchase of assets (such as physical IT infrastructure/machinery). These assets are amortized (depreciate in value) over time.\n",
    " - **OpEx** (Operational Expenditure): Day-to-day expenditures, requiring no up-front capital cost.\n",
    " - \"Shared responsibility model\":\n",
    " - **Serverless Computing**: Cloud-based computing in which the physical infrastucture is flexibly and automatically allocated in the back-end, i.e. there is no requirement on the customer to allocate physical resources (similar to Paas). Serverless architectures are **event driven** (triggered by some event).\n",
    " - **SLA**: Service-level agreement (e.g. between a provider and a client), e.g. how much database uptime is expected of the provider.\n",
    "\n",
    " - **SaaS**: Software as a service. Like you **use someone else's app online** (like Google Docs).\n",
    " - **PaaS**: Platform as a service. **You can deploy your app, and also have runtime environments for developing/testing**. Examples: Heroku, PythonAnywhere, AWS Elastic Beanstalk.\n",
    " - **IaaS**: Infrastructure as a service. Like a **virtual data center, complete with servers and storage**. Also includes availability of **computing power for data analysis / data mining**. Examples: **AWS, Google Compute Engine, Microsoft Azure**. This is what an IT administrator would work with, or I suppose an analyst doing data mining.\n",
    "\n",
    "\n",
    " - **Hybrid Cloud**:\n",
    " - **Private Cloud**:\n",
    " - **Public Cloud**:\n",
    "\n",
    "Data Warehouses, Lakes, Lakehouses\n",
    "========\n",
    "\n",
    " - **Database**: Intended to store real-time information of e.g. a business. Used in everyday, realtime transactions.\n",
    " - **Data Warehouse**: Intended to store *historical* data. Not updated in real-time; for historical analytics.\n",
    "   - **OLTP**: OnLine Transactional Processing (e.g. Create, Read, Update, Delete initiated by e.g. a customer transaction)\n",
    "   - **OLAP**: OnLine Analytical Processing, for operations on aggregated data. Configured differently for speed reasons.\n",
    "   - The data in a Data warehouse can be **denormalized** in order to improve the speed of analytical queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docker\n",
    "========\n",
    "\n",
    "Terminology:\n",
    " - **Virtual machines**: Complete operating system running. It directly uses the hardware of the system using something called the **hypervisor**.\n",
    "    - Uses a lot more space\n",
    "    - Takes some time to boot up the OS\n",
    "    - Do you have to update a VM with software patches???\n",
    " - **A container**, on the other hand, simply virtualizes the **operating system**. No hypervisor.\n",
    " - **\"Bare metal\"**: Like totally the hardware man\n",
    " - **UAT**: ???\n",
    " - **Stage**: ???\n",
    " - **chroot**: A linux command, \"change root directory\" so that the terminal / process only sees that root directory.\n",
    " - **Image**: the instructions for building your container. Also a snapshot of a container. It is made up of of layers.\n",
    " - **Layers**: e.g. a base layer (Ubuntu), another layer (software), then dependencies, configurations, ...\n",
    " - **Container**: A running **instance** of a docker **image**.\n",
    "\n",
    "**3 Stages**:\n",
    " - Build images\n",
    " - Ship images\n",
    " - Run images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docker for CVMFS (on a Mac)\n",
    "-------\n",
    "\n",
    "```bash\n",
    "brew install --cask osxfuse\n",
    "curl https://ecsft.cern.ch/dist/cvmfs/cvmfs-2.8.0/cvmfs-service-2.8.0-1.x86_64.docker.tar.gz\n",
    "cat cvmfs-service-2.8.0-1.x86_64.docker.tar.gz | docker load\n",
    "```\n",
    "\n",
    "To run the container, do:\n",
    "```bash\n",
    "docker run -d --rm -e CVMFS_CLIENT_PROFILE=single   -e CVMFS_REPOSITORIES=sft.cern.ch   --cap-add SYS_ADMIN   --device /dev/fuse --volume /cvmfs:/cvmfs:shared cvmfs/service:2.8.0-1\n",
    "```\n",
    "\n",
    "Volumes\n",
    "--------\n",
    "\n",
    "To persist data (on e.g. the local machine) in a way that docker knows about the data, and can connect it back up with a new container, you can do e.g.:\n",
    "\n",
    "```bash\n",
    "docker volume create my-database\n",
    "```\n",
    "\n",
    "docker run -dp 3000:3000 -v todo-db:/etc/todos getting-started\n",
    "\n",
    "An Example DockerFile\n",
    "---------\n",
    "```docker\n",
    "# syntax=docker/dockerfile:1\n",
    "\n",
    "FROM python:3.8-slim-buster\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "COPY requirements.txt requirements.txt\n",
    "RUN pip3 install -r requirements.txt\n",
    "\n",
    "COPY . .\n",
    "\n",
    "CMD [ \"python3\", \"-m\" , \"flask\", \"run\", \"--host=0.0.0.0\"]\n",
    "```\n",
    "\n",
    "Starting a Dev-mode container\n",
    "---------\n",
    "\n",
    "You can start a container that has some base image, and then mount the local directory and (somehow?) get the container to look for local changes. When local changes are detected, the container stops, rebuilds, and restarts, so you can develop without having to set up a local vm or anything! Pretty neat. Not sure exactly how this works in fact.\n",
    "\n",
    "Docker Compose\n",
    "--------\n",
    "\n",
    "These are yaml files that allow for multi-container applications to be spun up quickly. An example file is below:\n",
    "\n",
    "```yaml\n",
    "version: \"3.7\"\n",
    "services:\n",
    "  # \"app\" is the name of the service, below:\n",
    "  app:\n",
    "    image: node:12-alpine\n",
    "    command: sh -c \"yarn install && yarn run dev\"\n",
    "    ports:\n",
    "      - 3000:3000\n",
    "    working_dir: /app\n",
    "    volumes:\n",
    "      - ./:/app\n",
    "    environment:\n",
    "      MYSQL_HOST: mysql\n",
    "      MYSQL_USER: root\n",
    "\n",
    "  # Another service, called \"mysql\"\n",
    "  mysql:\n",
    "    image: mysql:5.7\n",
    "    volumes:\n",
    "      - todo-mysql-data:/var/lib/mysql\n",
    "    \n",
    "  # If you use a volume, you must schedule it as a service in a Docker Compose file, see below\n",
    "  volumes:\n",
    "    # Below: no info == default volume properties\n",
    "    todo-mysql-data:\n",
    "```\n",
    "\n",
    "Then run it with (`-d` means \"in the background\"):\n",
    "```bash\n",
    "docker-compose up -d\n",
    "```\n",
    "\n",
    "and to stop it, you do:\n",
    "```\n",
    "docker compose down\n",
    "```\n",
    "\n",
    "Other Things of Note:\n",
    "--------\n",
    " - Use `docker scan <image>` to check for vulnerabilities in your images\n",
    " - Use `docker image history --no-trunc <image>` to see how each layer is built. Also useful for seeing the size of a layer.\n",
    "\n",
    "Network\n",
    "--------\n",
    "\n",
    "```bash\n",
    "docker network create mysqlnet\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Microsoft Azure\n",
    "========\n",
    "\n",
    " - Benefits of Cloud Computing: **Scalability, High Availability, Elasticity, Agility, Disaster Recovery**\n",
    " - Microsoft Azure uses **virtual machines** in the backend, using a **hypervisor** to perform the virtualization.\n",
    " - **Hypervisor**: A hypervisor is a kind of emulator; it is computer software, firmware or hardware that creates and runs virtual machines.\n",
    " - **Orchestrator**: Part of the Azure backend that deals with responding to user requests, and it has a web API\n",
    " - **Fabric controller**: Part of the backend that creates the new virtual machine on the server.\n",
    "\n",
    "\n",
    " - **Azure Marketplaces** allows you to integrate someone else's data solutions into your workflow... interesting.\n",
    "\n",
    "\n",
    " - **Compute Services**: Virtual machines, containers, serverless computing (microservices)\n",
    " - **Cloud Storage**: Disks attached to virtual machines, fileshares, databases\n",
    " - **Networking Feastures**: Allows creation of private network connections, ...???\n",
    " - **Integration**: Allows for workflows to be created...\n",
    "\n",
    "\n",
    " - Internet of Things (IoT) Hub, IoT Central, and Azure Sphere \n",
    " - Azure Synapse Analytics, HDInsight, and Azure Databricks \n",
    " - Azure Machine Learning, Cognitive Services and Azure Bot Service \n",
    " - Serverless computing solutions:Azure Functions and Logic Apps \n",
    " - Azure DevOps, GitHub, GitHub Actions, and Azure DevTest Labs \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Service (Computing)  | Description  |\n",
    "| :---      | :---  |\n",
    "| Azure Virtual Machines  | Windows or Linux virtual machines (VMs) hosted in Azure  |\n",
    "| Azure Virtual Machine Scale Sets  | Scaling for Windows or Linux VMs hosted in Azure  |\n",
    "| Azure Kubernetes Service  | Cluster management for VMs that run containerized services  |\n",
    "| Azure Service Fabric  | Distributed systems platform that runs in Azure or on-premises  |\n",
    "| Azure Batch  | Managed service for parallel and high-performance computing applications  |\n",
    "| Azure Container Instances  | Containerized apps run on Azure without provisioning servers or VMs  |\n",
    "| Azure Functions  | An event-driven, serverless compute service  |\n",
    "\n",
    "\n",
    "| Service (Networking)  | Description  |\n",
    "| :---      | :---  |\n",
    "| Azure Virtual Network     | Connects VMs to incoming virtual private network (VPN) connections |\n",
    "| Azure Load Balancer       | Balances inbound and outbound connections to applications or service endpoints |\n",
    "| Azure Application Gateway | Optimizes app server farm delivery while increasing application security |\n",
    "| Azure VPN Gateway         | Accesses Azure Virtual Networks through high-performance VPN gateways |\n",
    "| Azure DNS                 | Provides ultra-fast DNS responses and ultra-high domain availability |\n",
    "| Azure Content Delivery Network  | Delivers high-bandwidth content to customers globally |\n",
    "| Azure DDoS Protection     | Protects Azure-hosted applications from distributed denial of service (DDOS) attacks |\n",
    "| Azure Traffic Manager     | Distributes network traffic across Azure regions worldwide |\n",
    "| Azure ExpressRoute        | Connects to Azure over high-bandwidth dedicated secure connections |\n",
    "| Azure Network Watcher     | Monitors and diagnoses network issues by using scenario-based analysis |\n",
    "| Azure Firewall            | Implements high-security, high-availability firewall with unlimited scalability |\n",
    "| Azure Virtual WAN         | Creates a unified wide area network (WAN) that connects local and remote sites |\n",
    "\n",
    "| Service (Storage)  | Description  |\n",
    "| :---      | :---  |\n",
    "| Azure Blob storage   | Storage service for very large objects, such as video files or bitmaps  |\n",
    "| Azure File storage   | File shares that can be accessed and managed like a file server  |\n",
    "| Azure Queue storage  | A data store for queuing and reliably delivering messages between applications  |\n",
    "| Azure Table storage  | A NoSQL store that hosts unstructured data independent of any schema  |\n",
    "\n",
    "| Service (Databases)  | Description  |\n",
    "| :---      | :---  |\n",
    "|  Azure Cosmos DB  | Globally distributed database that supports NoSQL options  |\n",
    "| Azure SQL Database     | Fully managed relational database with auto-scale, integral intelligence, and robust security  |\n",
    "| Azure Database for MySQL    | Fully managed and scalable MySQL relational database with high availability and security  |\n",
    "| Azure Database for PostgreSQL  | Fully managed and scalable PostgreSQL relational database with high availability and security  |\n",
    "| SQL Server on Azure Virtual Machines  | Service that hosts enterprise SQL Server apps in the cloud  |\n",
    "| Azure Synapse Analytics  | Fully managed data warehouse with integral security at every level of scale at no extra cost  |\n",
    "| Azure Database Migration Service  | Service that migrates databases to the cloud with no application code changes\n",
    "| Azure Cache for Redis  | Fully managed service caches frequently used and static data to reduce data and application latency  |\n",
    "| Azure Database for MariaDB  | Fully managed and scalable MariaDB relational database with high availability and security  |\n",
    "\n",
    "| Service (IoT)  | Description  |\n",
    "| :---      | :---  |\n",
    "| IoT Central  | Fully managed global IoT software as a service (SaaS) solution that makes it easy to connect, monitor, and manage IoT assets at scale  |\n",
    "| Azure IoT Hub  | Messaging hub that provides secure communications between and monitoring of millions of IoT devices  |\n",
    "| IoT Edge  | Fully managed service that allows data analysis models to be pushed directly onto IoT devices, which allows them to react quickly to state changes without needing to consult cloud-based AI models  |\n",
    "\n",
    "| Service (Big Data Analytics)  | Description  |\n",
    "| :---  | :---  |\n",
    "| Azure Synapse Analytics  | Run analytics at a massive scale by using a cloud-based enterprise data warehouse that takes advantage of massively parallel processing to run complex queries quickly across petabytes of data.  |\n",
    "| Azure HDInsight  | Process massive amounts of data with managed clusters of Hadoop clusters in the cloud.  |\n",
    "| Azure Databricks  | Integrate this collaborative Apache Spark-based analytics service with other big data services in Azure.  |\n",
    "\n",
    "| Service (ML / AI)  | Description  |\n",
    "| :---  | :---  |\n",
    "| Azure Machine Learning Service  | Cloud-based environment you can use to develop, train, test, deploy, manage, and track machine learning models. It can auto-generate a model and auto-tune it for you. It will let you start training on your local machine, and then scale out to the cloud.  |\n",
    "| Azure Machine Learning Studio  | Collaborative visual workspace where you can build, test, and deploy machine learning solutions by using prebuilt machine learning algorithms and data-handling modules.  |\n",
    "\n",
    "| Service (Cognitive AI)  | Description  |\n",
    "| :---  | :---  |\n",
    "| Vision  | Use image-processing algorithms to smartly identify, caption, index, and moderate your pictures and videos.  |\n",
    "| Speech  | Convert spoken audio into text, use voice for verification, or add speaker recognition to your app.  |\n",
    "| Knowledge mapping  | Map complex information and data to solve tasks such as intelligent recommendations and semantic search.  |\n",
    "| Bing Search  | Add Bing Search APIs to your apps and harness the ability to comb billions of webpages, images, videos, and news with a single API call.  |\n",
    "| Natural Language processing  | Allow your apps to process natural language with pre-built scripts, evaluate sentiment, and learn how to recognize what users want.  |\n",
    "\n",
    "| Service (DevOps)  | Description  |\n",
    "| :---  | :---  |\n",
    "| Azure DevOps  | Use development collaboration tools such as high-performance pipelines, free private Git repositories, configurable Kanban boards, and extensive automated and cloud-based load testing. Formerly known as Visual Studio Team Services.  |\n",
    "| Azure DevTest Labs  | Quickly create on-demand Windows and Linux environments to test or demo applications directly from deployment pipelines.  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apache Kafka\n",
    "=======\n",
    "\n",
    " - A software / distributed system for broadcasting \"events\" that are listened to by other services\n",
    "   - Can be used to decouple applications from one another (no more complicated dependencies, just broadcasters/listeners)\n",
    " - Can used for **decoupling**, **messaging**, **location tracking**, **data gathering**\n",
    " - Built on for core APIs:\n",
    "    - **Producer API**: Topics (persisted to physical storage, for some amount of time\n",
    "    - **Consumer API** ingests that data in real-time or in the past\n",
    "    - **Streams API**: Transforms/analyzes/aggregates data and re-broadcasts them as a new Topic/Stream\n",
    "    - **Connector API**: Integration layer for configuring data sources (e.g. \"reusable producers and consumers\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Apache Spark\n",
    "=======\n",
    "\n",
    "Setting up a version of Apache Spark can be a bit tricky; I found this useful guide to help avoid some of the biggest issues: https://towardsdatascience.com/how-to-get-started-with-pyspark-1adc142456ec\n",
    "\n",
    " - **DataFrame API**: Similar to e.g. Pandas DataFrames.\n",
    " - **RDD API**: The \"Resilient Distributed Dataset\", is an **interface** to a sequence of data objects located in a collection of machines. A subset of the DataFrame API. This was the original data structure of Apache Spark.\n",
    " - **Dataset API**: *Only available in Java and Scala*, this is some combination between DataFrames and RDD.\n",
    "\n",
    "One key important feature of Spark is that it features data *transformations* and *actions*. *Transformations* are executed \"lazily,\" e.g. because they do not immediately require an output, Spark will wait until there is an action (requiring an output) to perform the transformation(s)+action, which optimizes its performance.\n",
    "\n",
    "You can get pyspark by running the following -- **note, however, that pyspark is insufficient to set up a standalone spark cluster**.\n",
    "```bash\n",
    "pip3 install pyspark\n",
    "```\n",
    "\n",
    "Otherwise, you should go to the Apache Spark website and download one of the latest versions (as a tgz), and unzip it in your home directory.\n",
    "\n",
    "Note that you will have to make sure you have downloaded the Java Development Kit (JDK), e.g. here: https://www.oracle.com/java/technologies/javase/javase-jdk8-downloads.html.\n",
    "(Note that we are installing JDK 8, because Spark 2.x apparently does not work with Java versions >8.)\n",
    "\n",
    "Add the following to your `.bash_profile` script:\n",
    "\n",
    "```bash\n",
    "export JAVA_HOME=$(/usr/libexec/java_home)\n",
    "export PATH=$HOME/spark-3.1.2-bin-hadoop3.2/bin:$PATH\n",
    "export PYSPARK_PYTHON=python3\n",
    "```\n",
    "\n",
    "Then you can use the command-line interface simply by typing:\n",
    "```bash\n",
    "pyspark\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some More Concepts:\n",
    "========\n",
    "\n",
    " - **Wide vs narrow Transformations**: A wide transformation is one that occurs across multiple nodes of a spark cluster, e.g. `orderBy` or `groupBy`. Narrow transformations include e.g. `filter` and `contains` (applied to individual rows). Wide transformations must be used carefully, because they incur a fairly hefty time penalty."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
