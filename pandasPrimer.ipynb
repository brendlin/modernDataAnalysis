{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas Primer\n",
    "==========\n",
    "\n",
    "A collection of code snippets to serve as a reference point for performing pandas operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read\n",
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ninja_pv_wind_profiles_singleindex.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadFile(filename) :\n",
    "    if 'csv' in filename:\n",
    "        df = pd.read_csv(io.StringIO(decoded.decode('utf-8')))\n",
    "    elif 'xls' in filename:\n",
    "        df = pd.read_excel(io.BytesIO(decoded))\n",
    "    elif 'json' in filename :\n",
    "        df = pd.read_json(io.BytesIO(decoded))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape, Columns, summary, etc\n",
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the dataset smaller during setup\n",
    "df = df[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A quick look at the dataset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert date columns to DateTime object\n",
    "========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time_dt'] = pd.to_datetime(df['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df['time_dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns :\n",
    "    if 'AT' in i : print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=[30,10])\n",
    "ax.plot(np.array(df['time_dt'][:200]),np.array(df['AT_pv_national_current'][:200]),label='AT')\n",
    "ax.plot(np.array(df['time_dt'][:200]),np.array(df['AT_wind_national_current'][:200]),label='AT wind')\n",
    "ax.plot(np.array(df['time_dt'][:200]),np.array(df['BE_pv_national_current'][:200]),label='Belgium solar')\n",
    "ax.plot(np.array(df['time_dt'][:200]),np.array(df['BE_wind_offshore_current'][:200]),label='Belgium wind offshore')\n",
    "ax.plot(np.array(df['time_dt'][:200]),np.array(df['SE_pv_national_current'][:200]),label='Sweden')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2,ax2 = plt.subplots(figsize=[10,10])\n",
    "ax2.scatter(df['AT_wind_national_current'],df['BE_wind_offshore_current'],label='AT/BE wind corr')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT WORKING\n",
    "#df.resample('7D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column Manipulation\n",
    "--------\n",
    "\n",
    "**Shift**: e.g.\n",
    "```python\n",
    "df['deviceTime_end'] = df['deviceTime'].shift(1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Meaningless() :\n",
    "    # Subset that has the BG settings\n",
    "    pd_smbg = pd_all[pd_all['type'] == 'smbg'][['deviceTime','value']]\n",
    "    #pd_smbg['deviceTime_dt'] = pd.to_datetime(pd_all['deviceTime'])\n",
    "\n",
    "    # Subset for containers\n",
    "    columns_to_save = ['deviceTime','type','subType','duration','normal','extended','carbInput','value']\n",
    "    pd_containers = pd_all[(pd_all['type'] == 'wizard') | (pd_all['type'] == 'bolus')][columns_to_save]\n",
    "\n",
    "    # Subset for basal\n",
    "    columns_to_save = ['deviceTime','deliveryType','percent','rate','suppressed','duration']\n",
    "\n",
    "    # Step 1: Pick out all the basals\n",
    "    pd_tmp1 = pd_all[(pd_all['type'] == 'basal')][columns_to_save]\n",
    "\n",
    "    # Step 2: Save only temp, suspend, or entries just after temp, suspend\n",
    "    # [:] to avoid a SettingWithCopyWarning\n",
    "    pd_tmp2 = pd_tmp1[:][(pd_tmp1['deliveryType'] == 'temp') | (pd_tmp1['deliveryType'].shift(-1) == 'temp') |\n",
    "                         (pd_tmp1['deliveryType'] == 'suspend') | (pd_tmp1['deliveryType'].shift(-1) == 'suspend')\n",
    "                         ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenation (instead of `df['x'] = list(...)`)\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame({'a':list(range(10))})\n",
    "b = pd.DataFrame({'b':list(range(10)),'c':list(range(10))})\n",
    "pd.concat([pd.DataFrame(),a],axis=1)\n",
    "pd.concat([a,b],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using np.Vectorize\n",
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Meaningless() :\n",
    "    def getDeviceTimeEndFixed(deviceTime,deviceTime_end,duration) :\n",
    "        scheduled_end = pd.to_datetime(deviceTime) + datetime.timedelta(milliseconds=duration)\n",
    "        if type(deviceTime_end) != type('') :\n",
    "            return scheduled_end.strftime('%Y-%m-%dT%H:%M:%S')\n",
    "        return min(pd.to_datetime(deviceTime_end),scheduled_end).strftime('%Y-%m-%dT%H:%M:%S')\n",
    "\n",
    "    # Step 3: Save the end-times of temp and suspend based on this skimmed pd. Save fixed percent.\n",
    "\n",
    "    pd_tmp2['deviceTime_end_fixed'] = np.vectorize(getDeviceTimeEndFixed)(pd_tmp2['deviceTime'],pd_tmp2['deviceTime_end'],pd_tmp2['duration'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling missing or corrupted data\n",
    "-----------\n",
    "`isnull()`, `dropna()`, `fillna(0)` are examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datetime manipulation\n",
    "-------\n",
    "\n",
    "```\n",
    "pd.to_datetime(bgs.iloc[i]['deviceTime']) < start_time_dt64 :\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge (or join)\n",
    "======="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix() :\n",
    "    pd.merge(a,b,how='outer',on='blah',suffixes=['asdf','sdfg'])\n",
    "    \n",
    "# There is also something called join..!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
